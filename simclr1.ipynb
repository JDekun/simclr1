{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPFxqdFuNRTO",
        "outputId": "c61c0166-14ad-45cf-992f-080da3a45b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm1d'>.\n",
            "# Model Params: 24.62M FLOPs: 1.31G\n",
            "  0% 0/97 [00:00<?, ?it/s]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Train Epoch: [1/10] Loss: 6.9085:   1% 1/97 [00:17<27:28, 17.17s/it]Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Train Epoch: [1/10] Loss: 6.3302: 100% 97/97 [02:16<00:00,  1.41s/it]\n",
            "Feature extracting: 100% 98/98 [00:22<00:00,  4.38it/s]\n",
            "Test Epoch: [1/10] Acc@1:40.32% Acc@5:89.20%: 100% 20/20 [00:07<00:00,  2.62it/s]\n",
            "Train Epoch: [2/10] Loss: 5.9984: 100% 97/97 [02:16<00:00,  1.41s/it]\n",
            "Feature extracting: 100% 98/98 [00:22<00:00,  4.34it/s]\n",
            "Test Epoch: [2/10] Acc@1:43.20% Acc@5:90.91%: 100% 20/20 [00:07<00:00,  2.59it/s]\n",
            "Train Epoch: [3/10] Loss: 5.8788: 100% 97/97 [02:16<00:00,  1.41s/it]\n",
            "Feature extracting: 100% 98/98 [00:22<00:00,  4.30it/s]\n",
            "Test Epoch: [3/10] Acc@1:46.13% Acc@5:92.14%: 100% 20/20 [00:07<00:00,  2.63it/s]\n",
            "Train Epoch: [4/10] Loss: 5.8076: 100% 97/97 [02:17<00:00,  1.41s/it]\n",
            "Feature extracting: 100% 98/98 [00:23<00:00,  4.19it/s]\n",
            "Test Epoch: [4/10] Acc@1:49.29% Acc@5:93.26%: 100% 20/20 [00:07<00:00,  2.59it/s]\n",
            "Train Epoch: [5/10] Loss: 5.7609: 100% 97/97 [02:16<00:00,  1.41s/it]\n",
            "Feature extracting: 100% 98/98 [00:22<00:00,  4.31it/s]\n",
            "Test Epoch: [5/10] Acc@1:50.52% Acc@5:94.04%: 100% 20/20 [00:07<00:00,  2.55it/s]\n",
            "Train Epoch: [6/10] Loss: 5.7246: 100% 97/97 [02:17<00:00,  1.42s/it]\n",
            "Feature extracting: 100% 98/98 [00:22<00:00,  4.30it/s]\n",
            "Test Epoch: [6/10] Acc@1:52.71% Acc@5:94.55%: 100% 20/20 [00:07<00:00,  2.60it/s]\n",
            "Train Epoch: [7/10] Loss: 5.6984: 100% 97/97 [02:16<00:00,  1.41s/it]\n",
            "Feature extracting: 100% 98/98 [00:22<00:00,  4.30it/s]\n",
            "Test Epoch: [7/10] Acc@1:54.81% Acc@5:95.48%: 100% 20/20 [00:07<00:00,  2.64it/s]\n",
            "Train Epoch: [8/10] Loss: 5.6666: 100% 97/97 [02:17<00:00,  1.42s/it]\n",
            "Feature extracting: 100% 98/98 [00:23<00:00,  4.17it/s]\n",
            "Test Epoch: [8/10] Acc@1:56.28% Acc@5:95.91%: 100% 20/20 [00:07<00:00,  2.62it/s]\n",
            "Train Epoch: [9/10] Loss: 5.6433: 100% 97/97 [02:16<00:00,  1.40s/it]\n",
            "Feature extracting: 100% 98/98 [00:22<00:00,  4.33it/s]\n",
            "Test Epoch: [9/10] Acc@1:57.49% Acc@5:96.08%: 100% 20/20 [00:07<00:00,  2.65it/s]\n",
            "Train Epoch: [10/10] Loss: 5.6209: 100% 97/97 [02:16<00:00,  1.41s/it]\n",
            "Feature extracting: 100% 98/98 [00:22<00:00,  4.32it/s]\n",
            "Test Epoch: [10/10] Acc@1:58.21% Acc@5:96.31%: 100% 20/20 [00:07<00:00,  2.53it/s]\n"
          ]
        }
      ],
      "source": [
        "!python main.py --batch_size 4 --epochs 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKMfvl2nNTB_",
        "outputId": "26a2a58e-d39b-4723-9878-6ad507351613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Files already downloaded and verified\n",
            "Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O2\n",
            "cast_model_type        : torch.float16\n",
            "patch_torch_functions  : False\n",
            "keep_batchnorm_fp32    : True\n",
            "master_weights         : True\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
            "[INFO] Register count_convNd() for <class 'torch.nn.modules.conv.Conv2d'>.\n",
            "[INFO] Register count_normalization() for <class 'torch.nn.modules.batchnorm.BatchNorm2d'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.activation.ReLU'>.\n",
            "[INFO] Register zero_ops() for <class 'torch.nn.modules.container.Sequential'>.\n",
            "[INFO] Register count_adap_avgpool() for <class 'torch.nn.modules.pooling.AdaptiveAvgPool2d'>.\n",
            "[INFO] Register count_linear() for <class 'torch.nn.modules.linear.Linear'>.\n",
            "# Model Params: 23.52M FLOPs: 1.31G\n",
            "Train Epoch: [1/10] Loss: 1.5485 ACC@1: 44.68% ACC@5: 89.26%: 100% 49/49 [00:41<00:00,  1.17it/s]\n",
            "Test Epoch: [1/10] Loss: 1.2156 ACC@1: 56.08% ACC@5: 95.40%: 100% 10/10 [00:06<00:00,  1.56it/s]\n",
            "Train Epoch: [2/10] Loss: 1.3634 ACC@1: 51.09% ACC@5: 92.97%: 100% 49/49 [00:40<00:00,  1.22it/s]\n",
            "Test Epoch: [2/10] Loss: 1.1790 ACC@1: 56.79% ACC@5: 95.91%: 100% 10/10 [00:06<00:00,  1.53it/s]\n",
            "Train Epoch: [3/10] Loss: 1.3312 ACC@1: 52.25% ACC@5: 93.54%: 100% 49/49 [00:40<00:00,  1.22it/s]\n",
            "Test Epoch: [3/10] Loss: 1.1592 ACC@1: 57.85% ACC@5: 95.94%: 100% 10/10 [00:06<00:00,  1.56it/s]\n",
            "Train Epoch: [4/10] Loss: 1.3251 ACC@1: 52.86% ACC@5: 93.60%: 100% 49/49 [00:41<00:00,  1.18it/s]\n",
            "Test Epoch: [4/10] Loss: 1.1362 ACC@1: 59.23% ACC@5: 96.14%: 100% 10/10 [00:06<00:00,  1.56it/s]\n",
            "Train Epoch: [5/10] Loss: 1.3046 ACC@1: 53.52% ACC@5: 93.85%: 100% 49/49 [00:40<00:00,  1.22it/s]\n",
            "Test Epoch: [5/10] Loss: 1.1398 ACC@1: 59.04% ACC@5: 96.27%: 100% 10/10 [00:06<00:00,  1.57it/s]\n",
            "Train Epoch: [6/10] Loss: 1.3018 ACC@1: 53.73% ACC@5: 93.72%: 100% 49/49 [00:40<00:00,  1.21it/s]\n",
            "Test Epoch: [6/10] Loss: 1.1256 ACC@1: 59.40% ACC@5: 96.34%: 100% 10/10 [00:06<00:00,  1.50it/s]\n",
            "Train Epoch: [7/10] Loss: 1.2945 ACC@1: 53.95% ACC@5: 93.95%: 100% 49/49 [00:42<00:00,  1.14it/s]\n",
            "Test Epoch: [7/10] Loss: 1.1395 ACC@1: 59.14% ACC@5: 96.13%: 100% 10/10 [00:06<00:00,  1.55it/s]\n",
            "Train Epoch: [8/10] Loss: 1.2895 ACC@1: 54.15% ACC@5: 93.95%: 100% 49/49 [00:41<00:00,  1.18it/s]\n",
            "Test Epoch: [8/10] Loss: 1.0854 ACC@1: 61.41% ACC@5: 96.32%: 100% 10/10 [00:06<00:00,  1.54it/s]\n",
            "Train Epoch: [9/10] Loss: 1.2830 ACC@1: 54.54% ACC@5: 94.01%: 100% 49/49 [00:41<00:00,  1.17it/s]\n",
            "Test Epoch: [9/10] Loss: 1.0859 ACC@1: 61.28% ACC@5: 96.48%: 100% 10/10 [00:07<00:00,  1.39it/s]\n",
            "Train Epoch: [10/10] Loss: 1.2773 ACC@1: 54.64% ACC@5: 93.93%: 100% 49/49 [00:40<00:00,  1.21it/s]\n",
            "Test Epoch: [10/10] Loss: 1.0857 ACC@1: 61.09% ACC@5: 96.74%: 100% 10/10 [00:06<00:00,  1.57it/s]\n"
          ]
        }
      ],
      "source": [
        "!python linear.py --batch_size 1024 --epochs 10"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "simclr_1.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "cc9daa352394ac6fd6b224fdae94757fb224b4aab069bc0189ad8c000c678227"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
